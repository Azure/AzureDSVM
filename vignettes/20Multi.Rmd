---
title = "Using Azure Data Science Virtual Machine: Multi-deployment of DSVMs Quick Start"
author= "Graham Williams"
output: rmarkdown::html_vignette
vignette: >
 %\VignetteIndexEntry{Vignette Title}
 %\VignetteEngine{knitr::rmarkdown}
 \usepackage[utf8]{inputenc}
---

# Use Case

Sometimes more than one DSVMs are needed.

* Multi-deployment of heterogeneous DSVMs may be required for a
  collaborative project where each of group members work on a machine
  with specific configuration. For instance, a powerful yet expensive
  machine is assigned to perform computation intensive tasks while a
  cheap one can be used for explorative or interactive tasks.

* Another common use case is for a Data Scientist to create their R
programs to analyse a dataset on their local compute platform (e.g., a
laptop with 6GB RAM running Ubuntu with R installed). Development is
performed with a subset of the full dataset (a random sample) that
will not exceed the available memory and will return results
quickly. When the experimental setup is complete the script can be
sent across to a considerably more capable compute engine on Azure,
possibly a cluster of servers to build models in parallel.

This tutorial deploys a collection/cluster of Linux Data Science
Virtual Machines (DSVMs) for the above two scenarios. In the latter
one, user distributes a trivial compute task over those servers,
collects the results and generates a report. Code is included but not
run to then delete the resource group if the resources are no longer
required. Once deleted consumption will cease.

This script is best run interactively to review its operation and to
ensure that the interaction with Azure completes.

# Setup

To get started load our Azure credentials as well as the user's ssh
public key. This information has been saved into a file with the name
<USER>_credentials.R where <USER> is your username.

```{r setup}
# Load the required subscription resources: TID, CID, and KEY.
# Also includes the ssh PUBKEY for the user.

USER <- Sys.info()[['user']]

source(paste0(USER, "_credentials.R"))
```

```{r packages}
# Load the required packages.

library(AzureSMR)    # Support for managing Azure resources.
library(AzureDSVM)    # Further support for the Data Scientist.
library(magrittr)    
library(dplyr)
```

```{r tuning}
# Parameters for this script: the name for the new resource group and
# its location across the Azure cloud. The resource name is used to
# name the resource group that we will create transiently for the
# purposes of this script.

# Create a random resource group to reduce likelihood of conflict with
# other users.

BASE <- 
  runif(4, 1, 26) %>%
  round() %>%
  letters[.] %>%
  paste(collapse="") %T>%
  {sprintf("Base name:\t\t%s", .) %>% cat("\n")}

RG <-
  paste0("my_dsvm_", BASE,"_rg_sea") %T>%
  {sprintf("Resource group:\t\t%s", .) %>% cat("\n")}

# Choose a data centre location.

LOC <-
  "southeastasia"  %T>%
  {sprintf("Data centre location:\t%s", .) %>% cat("\n")}

cat("\n")

COUNT <- 4                 # Number of VMs to deploy.
```

```{r connect}
# Connect to the Azure subscription and use this as the context for
# all of our activities.

context <- createAzureContext(tenantID=TID, clientID=CID, authKey=KEY)

# Check if the resource group already exists. Take note this script
# will not remove the resource group if it pre-existed.

rg_pre_exists <- existsRG(context, RG, LOC)

```
# Create Resource Group

Create the resource group within which all resources we create will be
grouped.

```{r create resource group}
if (! rg_pre_exists)
{
  # Create a new resource group into which we create the VMs and
  # related resources. Resource group name is RG. 
  
  # Note that to create a new resource group one needs to add access
  # control of Active Directory application at subscription level.

  azureCreateResourceGroup(context, RG, LOC) %>% cat("\n\n")

}

# Check that it now exists.

cat("Resource group", RG, "at", LOC,
    ifelse(!existsRG(context, RG, LOC), "does not exist.\n", "exists.\n"), "\n")
```

# Create a Cluster

Multi-deployment of DSVM can be achieved by calling
`deployDSVMCluster` function. Note the function is designed to
implicitly switch between cluster and collection of DSVMs, according
to the given inputs. That is, if the `hostname`, i.e., names of the
DSVMs consists of only one character string, the function will imply
the deployment is to create a cluster of homogeneous DSVMs (i.e., same
size), and use the unique machine name as the base, which is appended
with a sequential number to form a full hostname. If the `hostname`
is a vector of character strings, the function will create machines
with names specified in the name vector.

It is worth mentioning that a cluster of DSVMs is useful when
batch-based analytical job needs to be done in a desired computing
context, especially in a distributed manner across nodes of the
cluster. The distributed computing functionality is empowered by
Microsoft RevoScaleR parallel computing backend. The distributed and
parallel computing is socket-based and relies on SSH for secure
communication. To allow this communication across nodes,
`deployDSVMCluster` added inbound security rules into security group
of each DSVM in the cluster, and establish public key pairs for the
machines.

We can now deploy a cluster of homogeneous DSVMs. Each DSVM will be
named based on the *name* provided and sequentially numbered.

```{r deploy a cluster of DSVMs}
# Deploy a cluster of DSVMs.

cluster <- deployDSVMCluster(context, 
                             resource.group=RG, 
                             location=LOC, 
                             hostname=BASE,
                             username=USER, 
                             pubkey=PUBKEY,
                             count=COUNT)

# To validate the existence of deployed DSVMs.

for (i in 1:COUNT)
{
  vm <- cluster[i, "name"]
  fqdn <- cluster[i, "fqdn"]
  
  cat(vm, "\n")
  
  operateDSVM(context, RG, vm, operation="Check")
  
  # Send a simple system() command across to the new server to test
  # its existence. Expect a single line with an indication of how long
  # the server has been up and running.
  
  cmd <- paste("ssh -q",
               "-o StrictHostKeyChecking=no",
               "-o UserKnownHostsFile=/dev/null\\\n   ",
               fqdn,
               "uptime") %T>%
    {cat(., "\n")}
  cmd
  system(cmd)
  cat("\n")
}
```

# Create a Collection

We can also create a collection of Linux DSVMs each with a different
user and with public-key based authentication method. Name, username,
and size can also be configured.

```{r deploy a set of DSVMs, eval=FALSE}

# Deploy multiple DSVMs using deployDSVMCluster.

ldsvm_set <- deployDSVMCluster(context, 
                               resource.group=RG, 
                               location=LOC, 
                               count=COUNT, 
                               hostname=LDSVM, 
                               username=LUSER, 
                               pubkey=rep(PUBKEY, COUNT)) 

# Check the deployed machines?

for (vm in LDSVM)
{
  cat(vm, "\n")
  
  operateDSVM(context, RG, vm, operation="Check")
  
  # Send a simple system() command across to the new server to test
  # its existence. Expect a single line with an indication of how long
  # the server has been up and running.
  
  cmd <- paste("ssh -q",
               "-o StrictHostKeyChecking=no",
               "-o UserKnownHostsFile=/dev/null\\\n   ",
               paste0(vm, ".", LOC, ".cloudapp.azure.com"),
               "uptime") %T>%
    {cat(., "\n")}
  cmd
  system(cmd)
  cat("\n")
}
```

# Delete the Resource Group

```{r optionally delete resource group}
# Delete the resource group now that we have proved existence. There
# is probably no need to wait. Only delete if it did not pre-exist
# this script. Deletion seems to take 10 minutes or more.

if (! rg_pre_exists)
  azureDeleteResourceGroup(context, RG)
```

Once deleted we are consuming no more.
